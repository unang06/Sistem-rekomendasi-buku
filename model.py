# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hxiZ4jGruNnj7z2Sh7-ER0PBD3AA06BW
"""

import nltk
nltk.download('stopwords')

import re
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from nltk.corpus import stopwords

# Setup stemmer dan stopwords
factory = StemmerFactory()
stemmer = factory.create_stemmer()
stop_words = set(stopwords.words('indonesian'))

# Fungsi preprocessing
def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'[^a-zA-Z\s]', '', text)  # Hapus simbol dan angka
    tokens = text.split()
    tokens = [word for word in tokens if word not in stop_words]
    stemmed = [stemmer.stem(word) for word in tokens]
    return ' '.join(stemmed)

import requests
import pandas as pd

API_KEY = "AIzaSyCWtre-ogfgAL55nyLnNCnLmeo4cGUH7O8"
BASE_URL = "https://www.googleapis.com/books/v1/volumes"

def search_books(query, max_results=40):
    params = {
        'q': query,
        'key': API_KEY,
        'maxResults': max_results,
        'langRestrict': 'id'
    }

    try:
        response = requests.get(BASE_URL, params=params)
        response.raise_for_status()
        data = response.json()

        books = []
        for item in data.get('items', []):
            volume_info = item.get('volumeInfo', {})
            book = {
                'id': item.get('id'),
                'title': volume_info.get('title', 'No title'),
                'authors': ', '.join(volume_info.get('authors', ['Unknown'])),
                'genres': ', '.join(volume_info.get('categories', ['Unknown'])),
                'description': volume_info.get('description', 'No description'),
                'published_year': volume_info.get('publishedDate', '')[:4],
                'average_rating': volume_info.get('averageRating', 0),
                'thumbnail': volume_info.get('imageLinks', {}).get('thumbnail', '')
            }
            books.append(book)

        return pd.DataFrame(books)

    except Exception as e:
        print(f"Gagal mengambil data: {str(e)}")
        return pd.DataFrame()

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

def create_recommender(df):
    df['features'] = (df['genres'] + ' ' + df['description']).fillna('')
    df['features'] = df['features'].apply(preprocess_text)

    tfidf = TfidfVectorizer()
    tfidf_matrix = tfidf.fit_transform(df['features'])
    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
    return cosine_sim

# Contoh penggunaan untuk mencari buku
query = "sejarah indonesia"
books_df = search_books(query)

# Tampilkan 5 buku pertama
books_df[['title', 'authors', 'genres']].head()

# Buat model rekomendasi
cosine_sim = create_recommender(books_df)

# Rekomendasi untuk buku pertama
idx = 0
sim_scores = list(enumerate(cosine_sim[idx]))
sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]
recommended_books = [books_df.iloc[i[0]]['title'] for i in sim_scores]

recommended_books